{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vMbOeFqPumb"
      },
      "source": [
        "# Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HVsbYlGPPR2i",
        "outputId": "93680f80-0d7b-4ab1-815f-b9312f7b8f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: langchain 1.2.8\n",
            "Uninstalling langchain-1.2.8:\n",
            "  Successfully uninstalled langchain-1.2.8\n",
            "Found existing installation: langchain-core 1.2.9\n",
            "Uninstalling langchain-core-1.2.9:\n",
            "  Successfully uninstalled langchain-core-1.2.9\n",
            "\u001b[33mWARNING: Skipping langchain-community as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping langchain-text-splitters as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping langchain-groq as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: langsmith 0.6.9\n",
            "Uninstalling langsmith-0.6.9:\n",
            "  Successfully uninstalled langsmith-0.6.9\n",
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: pandas 2.2.2\n",
            "Uninstalling pandas-2.2.2:\n",
            "  Successfully uninstalled pandas-2.2.2\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==2.2.1\n",
            "  Downloading pandas-2.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting scikit-learn==1.4.2\n",
            "  Downloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting faiss-cpu==1.8.0\n",
            "  Downloading faiss_cpu-1.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting sentence-transformers==2.6.1\n",
            "  Downloading sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting transformers==4.38.2\n",
            "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymupdf==1.23.26\n",
            "  Downloading PyMuPDF-1.23.26-cp312-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting rank_bm25==0.2.2\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting langchain==0.1.20\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-core==0.1.53\n",
            "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-community==0.0.38\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting langchain-text-splitters==0.0.1\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting groq\n",
            "  Downloading groq-1.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.1) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2) (3.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.6.1) (4.67.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.6.1) (2.9.0+cpu)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.6.1) (1.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==2.6.1) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (3.20.3)\n",
            "Collecting huggingface-hub>=0.15.1 (from sentence-transformers==2.6.1)\n",
            "  Downloading huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (2.32.4)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.2)\n",
            "  Downloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.38.2) (0.7.0)\n",
            "Collecting PyMuPDFb==1.23.22 (from pymupdf==1.23.26)\n",
            "  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.20) (2.0.46)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.20) (3.13.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.20)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.20)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.1.20) (2.12.3)\n",
            "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.1.20)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.1.53) (1.33)\n",
            "Collecting packaging>=20.0 (from transformers==4.38.2)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.20)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.20)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.6.1) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.6.1) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.1.53) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.20) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.20) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.20) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.20) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.1.20) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.1) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.2) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.38.2) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.20) (3.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers==2.6.1) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.20)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers==2.6.1) (3.0.3)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m257.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m187.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m219.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m198.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMuPDF-1.23.26-cp312-none-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m294.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m348.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m237.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m141.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-1.0.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m566.4/566.4 kB\u001b[0m \u001b[31m229.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m124.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m251.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m233.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m232.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: tenacity, PyMuPDFb, packaging, numpy, mypy-extensions, typing-inspect, rank_bm25, pymupdf, pandas, marshmallow, huggingface-hub, faiss-cpu, tokenizers, scikit-learn, langsmith, groq, dataclasses-json, transformers, langchain-core, sentence-transformers, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.1.3\n",
            "    Uninstalling tenacity-9.1.3:\n",
            "      Successfully uninstalled tenacity-9.1.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 26.0\n",
            "    Uninstalling packaging-26.0:\n",
            "      Successfully uninstalled packaging-26.0\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface_hub 1.4.0\n",
            "    Uninstalling huggingface_hub-1.4.0:\n",
            "      Successfully uninstalled huggingface_hub-1.4.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.2\n",
            "    Uninstalling tokenizers-0.22.2:\n",
            "      Successfully uninstalled tokenizers-0.22.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 5.0.0\n",
            "    Uninstalling transformers-5.0.0:\n",
            "      Successfully uninstalled transformers-5.0.0\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 5.2.2\n",
            "    Uninstalling sentence-transformers-5.2.2:\n",
            "      Successfully uninstalled sentence-transformers-5.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.1 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "langgraph-prebuilt 1.0.7 requires langchain-core>=1.0.0, but you have langchain-core 0.1.53 which is incompatible.\n",
            "google-adk 1.24.0 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "xarray 2025.12.0 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
            "opencv-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "hdbscan 0.8.41 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\n",
            "google-cloud-bigquery 3.40.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "umap-learn 0.5.11 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\n",
            "langgraph-checkpoint 4.0.0 requires langchain-core>=0.2.38, but you have langchain-core 0.1.53 which is incompatible.\n",
            "db-dtypes 1.5.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "wheel 0.46.3 requires packaging>=24.0, but you have packaging 23.2 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyMuPDFb-1.23.22 dataclasses-json-0.6.7 faiss-cpu-1.8.0 groq-1.0.0 huggingface-hub-0.36.2 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.53 langchain-text-splitters-0.0.1 langsmith-0.1.147 marshmallow-3.26.2 mypy-extensions-1.1.0 numpy-1.26.4 packaging-23.2 pandas-2.2.1 pymupdf-1.23.26 rank_bm25-0.2.2 scikit-learn-1.4.2 sentence-transformers-2.6.1 tenacity-8.5.0 tokenizers-0.15.2 transformers-4.38.2 typing-inspect-0.9.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "e992ffa0804b42abbf3653da9c75b4bc",
              "pip_warning": {
                "packages": [
                  "numpy",
                  "packaging"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%pip uninstall -y \\\n",
        "  langchain langchain-core langchain-community langchain-text-splitters \\\n",
        "  langchain-groq langsmith numpy pandas\n",
        "\n",
        "%pip install --no-cache-dir \\\n",
        "  numpy==1.26.4 \\\n",
        "  pandas==2.2.1 \\\n",
        "  scikit-learn==1.4.2 \\\n",
        "  faiss-cpu==1.8.0 \\\n",
        "  sentence-transformers==2.6.1 \\\n",
        "  transformers==4.38.2 \\\n",
        "  pymupdf==1.23.26 \\\n",
        "  rank_bm25==0.2.2 \\\n",
        "  langchain==0.1.20 \\\n",
        "  langchain-core==0.1.53 \\\n",
        "  langchain-community==0.0.38 \\\n",
        "  langchain-text-splitters==0.0.1 \\\n",
        "  groq\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bRYfC0bPz10"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5TInuvkaPV6l"
      },
      "outputs": [],
      "source": [
        "import fitz  # PyMuPDF\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from sklearn.metrics import ndcg_score\n",
        "\n",
        "from langchain_text_splitters import (\n",
        "    RecursiveCharacterTextSplitter,\n",
        "    CharacterTextSplitter\n",
        ")\n",
        "\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
        "\n",
        "from langchain.retrievers import EnsembleRetriever, ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
        "from langchain_core.runnables import RunnablePassthrough,RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "#from langchain_ollama import OllamaLLM, ChatOllama #(use accordingly local ollama or cloud based llama deployment)\n",
        "from groq import Groq\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import json\n",
        "import re\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import logging\n",
        "\n",
        "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
        "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"sentence_transformers\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"langchain\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"langchain_text_splitters\").setLevel(logging.ERROR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c29ETM0IP2wi"
      },
      "source": [
        "# PDF Text Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7o8vleLPkBh",
        "outputId": "ef4aabdc-c1b0-42ee-c50f-736bd08f72a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted text length: 883449\n",
            "First 500 chars: Suspension System \n",
            "\n",
            "\n",
            "Inspection and Verification \n",
            "\n",
            "\n",
            "1.\n",
            "Road test. \n",
            "\n",
            "\n",
            "z Verify the customer concern by carrying out a road test on a smooth road. If any vibrations are \n",
            "\n",
            "\n",
            "apparent, refer to Section 100-04 . \n",
            "\n",
            "\n",
            "2.\n",
            "Inspect tires. \n",
            "\n",
            "\n",
            "z Check the tire pressure with all normal loads in the vehicle and the tires cold. Refer to the \n",
            "\n",
            "\n",
            "Vehicle Certification (VC) label. \n",
            "\n",
            "\n",
            "z Verify that all tires are sized to specification. Refer to the VC label. \n",
            "\n",
            "\n",
            "z Inspect the tires for incorrect wear and damage. Insta\n"
          ]
        }
      ],
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        blocks = page.get_text(\"blocks\")\n",
        "        for block in blocks:\n",
        "            if len(block) > 4 and block[4].strip():\n",
        "                text += block[4] + \"\\n\\n\"\n",
        "    doc.close()\n",
        "    return text.strip()\n",
        "\n",
        "pdf_path = \"sample-service-manual 1.pdf\"\n",
        "full_text = extract_text_from_pdf(pdf_path)\n",
        "print(f\"Extracted text length: {len(full_text)}\")\n",
        "print(f\"First 500 chars: {full_text[:500]}\")  # Checking whether file loaded properly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZOrp3y8QpQ8"
      },
      "source": [
        "# Embedding Model\n",
        "Using Sentence-Transformers for embeddings (all-MiniLM-L6-v2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LSvbp6Y6Qnf8"
      },
      "outputs": [],
      "source": [
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"all-MiniLM-L6-v2\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO7mJfyLQl2v"
      },
      "source": [
        "# Chunking Methods\n",
        "## We compare three chunking methods:\n",
        "\n",
        "1) Fixed-size chunks (simple, fast).\n",
        "2) Recursive character splitting (handles logical breaks).\n",
        "3) Semantic chunking (using MiniLM to split)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AgFUlBhpP-G5"
      },
      "outputs": [],
      "source": [
        "def fixed_chunking(text, size=500, overlap=50):\n",
        "    return CharacterTextSplitter(\n",
        "        chunk_size=size,\n",
        "        chunk_overlap=overlap\n",
        "    ).split_text(text)\n",
        "\n",
        "\n",
        "def recursive_chunking(text, size=500, overlap=50):\n",
        "    return RecursiveCharacterTextSplitter(\n",
        "        chunk_size=size,\n",
        "        chunk_overlap=overlap\n",
        "    ).split_text(text)\n",
        "\n",
        "\n",
        "def semantic_chunking(text, sim_threshold=0.75, min_len=120):\n",
        "    sentences = [s.strip() for s in text.split(\".\") if s.strip()]\n",
        "    if not sentences:\n",
        "        return []\n",
        "\n",
        "    embeddings = embedding_model.embed_documents(sentences)\n",
        "\n",
        "    chunks = []\n",
        "    current_chunk = [sentences[0]]\n",
        "\n",
        "    for i in range(1, len(sentences)):\n",
        "        sim = cosine_similarity(\n",
        "            [embeddings[i-1]],\n",
        "            [embeddings[i]]\n",
        "        )[0][0]\n",
        "\n",
        "        if sim >= sim_threshold:\n",
        "            current_chunk.append(sentences[i])\n",
        "        else:\n",
        "            chunk_text = \". \".join(current_chunk)\n",
        "            if len(chunk_text) >= min_len:\n",
        "                chunks.append(chunk_text)\n",
        "            current_chunk = [sentences[i]]\n",
        "\n",
        "    # last chunk\n",
        "    chunk_text = \". \".join(current_chunk)\n",
        "    if len(chunk_text) >= min_len:\n",
        "        chunks.append(chunk_text)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "chunking_methods = {\n",
        "    \"fixed\": fixed_chunking,\n",
        "    \"recursive\": recursive_chunking,\n",
        "    \"semantic\": semantic_chunking\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7nsDPhIQs98"
      },
      "source": [
        "# Define Retrievers\n",
        "Compare:\n",
        "\n",
        "1) Sparse: BM25.\n",
        "Dense:\n",
        "2) FAISS vector search.\n",
        "3) Hybrid: Ensemble of BM25 + Dense.\n",
        "4) With Re-ranker: Cross-encoder for re-ranking top-k results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "z2K8XgjdQrTB"
      },
      "outputs": [],
      "source": [
        "def create_bm25(chunks):\n",
        "    return BM25Retriever.from_texts(chunks, k=5)\n",
        "def create_dense(chunks):\n",
        "    vectorstore = FAISS.from_texts(chunks, embedding_model)\n",
        "    return vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
        "def create_hybrid(bm25, dense):\n",
        "    return EnsembleRetriever(\n",
        "        retrievers=[bm25, dense],\n",
        "        weights=[0.5, 0.5]\n",
        "    )\n",
        "def create_reranked(hybrid_retriever, top_n=5):\n",
        "    cross_encoder = HuggingFaceCrossEncoder(\n",
        "        model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "    )\n",
        "\n",
        "    compressor = CrossEncoderReranker(\n",
        "        model=cross_encoder,\n",
        "        top_n=top_n\n",
        "    )\n",
        "\n",
        "    return ContextualCompressionRetriever(\n",
        "        base_retriever=hybrid_retriever,\n",
        "        base_compressor=compressor\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goVSe-lJQyUH"
      },
      "source": [
        "# Queries and Ground Truth (Keyword-Based)\n",
        "\n",
        "**15 technical service manual queries** with keyword-based relevance criteria. Each query maps to specific component keywords and torque values. The `get_relevant_indices()` function identifies ground-truth chunks by requiring all keywords to be present."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mz001X_JQvvr"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# FEW HARD-CODED QUERIES + KEYWORDS (from Service Manual) FOR TESTING\n",
        "# Used to evaluate: chunking Ã— retriever\n",
        "# ============================================================\n",
        "\n",
        "queries = [\n",
        "    \"Torque for lower arm forward and rearward nuts\",\n",
        "    \"Torque for lower ball joint nut\",\n",
        "    \"Torque for upper ball joint nut\",\n",
        "    \"Torque for shock absorber lower nuts\",\n",
        "    \"Torque for shock absorber upper mount nuts\",\n",
        "    \"Torque for shock rod nut\",\n",
        "    \"Torque for stabilizer bar bracket nuts\",\n",
        "    \"Torque for stabilizer bar link nuts\",\n",
        "    \"Torque for tie-rod end nut\",\n",
        "    \"Torque for upper arm to frame nuts\",\n",
        "    \"Torque for wheel bearing and wheel hub bolts\",\n",
        "    \"Torque for wheel speed sensor bolt\",\n",
        "    \"Torque for brake disc shield bolts\",\n",
        "    \"Torque for brake hose bracket bolt\",\n",
        "    \"Torque for wheel lug nuts\",\n",
        "]\n",
        "\n",
        "KEYWORDS = {\n",
        "    0:  [\"lower arm\", \"350\", \"nm\"],\n",
        "    1:  [\"lower ball joint\", \"175\", \"nm\"],\n",
        "    2:  [\"upper ball joint\", \"115\"],\n",
        "    3:  [\"shock absorber\", \"lower\", \"90\"],\n",
        "    4:  [\"shock absorber\", \"upper\", \"63\"],\n",
        "    5:  [\"shock rod\", \"55\"],\n",
        "    6:  [\"stabilizer bar\", \"bracket\", \"55\"],\n",
        "    7:  [\"stabilizer bar\", \"link\", \"70\"],\n",
        "    8:  [\"tie-rod\", \"115\"],\n",
        "    9:  [\"upper arm\", \"frame\", \"150\"],\n",
        "    10: [\"wheel bearing\", \"hub\", \"175\"],\n",
        "    11: [\"wheel speed sensor\", \"18\"],\n",
        "    12: [\"brake disc shield\", \"17\"],\n",
        "    13: [\"brake hose bracket\", \"12\"],\n",
        "    14: [\"wheel nut\", \"150\"]\n",
        "}\n",
        "\n",
        "def get_relevant_indices(query_idx, chunks):\n",
        "    kws = KEYWORDS[query_idx]\n",
        "    return [\n",
        "        i for i, c in enumerate(chunks)\n",
        "        if all(k in c.lower() for k in kws)\n",
        "    ]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSfS65keQ3A5"
      },
      "source": [
        "# Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HbFijJSbQ0mn"
      },
      "outputs": [],
      "source": [
        "def recall_k(retrieved, relevant, k):\n",
        "    return len(set(retrieved[:k]) & set(relevant)) / len(relevant) if relevant else 0\n",
        "\n",
        "def mrr(retrieved, relevant):\n",
        "    for rank, idx in enumerate(retrieved, 1):\n",
        "        if idx in relevant:\n",
        "            return 1 / rank\n",
        "    return 0\n",
        "\n",
        "def precision_k(retrieved, relevant, k):\n",
        "    return len(set(retrieved[:k]) & set(relevant)) / k if k else 0\n",
        "\n",
        "def ndcg(retrieved, relevant, k):\n",
        "    y_true = [1 if i in relevant else 0 for i in retrieved[:k]]\n",
        "    y_ideal = sorted(y_true, reverse=True)\n",
        "    return ndcg_score([y_ideal], [y_true], k=k) if any(y_true) else 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMliXBbNQ7SU"
      },
      "source": [
        "# Retriever Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ThqBWb3wQ4Y0"
      },
      "outputs": [],
      "source": [
        "def evaluate_retriever(retriever, chunks, k=5):\n",
        "    scores = {\n",
        "        \"recall\": [],\n",
        "        \"mrr\": [],\n",
        "        \"precision\": [],\n",
        "        \"ndcg\": [],\n",
        "        \"latency\": []\n",
        "    }\n",
        "\n",
        "    for qi, query in enumerate(queries):\n",
        "        start = time()\n",
        "        docs = retriever.invoke(query)\n",
        "        latency = time() - start\n",
        "\n",
        "        retrieved_texts = [d.page_content for d in docs]\n",
        "        retrieved_indices = [\n",
        "            i for i, c in enumerate(chunks)\n",
        "            if c in retrieved_texts\n",
        "        ]\n",
        "\n",
        "        relevant = get_relevant_indices(qi, chunks)\n",
        "\n",
        "        scores[\"recall\"].append(recall_k(retrieved_indices, relevant, k))\n",
        "        scores[\"mrr\"].append(mrr(retrieved_indices, relevant))\n",
        "        scores[\"precision\"].append(precision_k(retrieved_indices, relevant, k))\n",
        "        scores[\"ndcg\"].append(ndcg(retrieved_indices, relevant, k))\n",
        "        scores[\"latency\"].append(latency)\n",
        "\n",
        "    return {m: np.mean(v) for m, v in scores.items()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "309bi1_vQ_e0"
      },
      "source": [
        "# Chunking Ã— Retriever Comparison\n",
        "\n",
        "To study the combined effect of chunking and retrieval, each chunking strategy is paired with every retriever.\n",
        "With 3 chunking methods and 4 retrievers, this results in 12 total configurations.\n",
        "\n",
        "## ðŸ”¹ Fixed Chunking\n",
        "- **Fixed + BM25**\n",
        "- **Fixed + Dense**\n",
        "- **Fixed + Hybrid**\n",
        "- **Fixed + Reranked Hybrid**\n",
        "\n",
        "## ðŸ”¹ Recursive Chunking\n",
        "- **Recursive + BM25**\n",
        "- **Recursive + Dense**\n",
        "- **Recursive + Hybrid**\n",
        "- **Recursive + Reranked Hybrid**\n",
        "\n",
        "## ðŸ”¹ Semantic Chunking\n",
        "- **Semantic + BM25**\n",
        "- **Semantic + Dense**\n",
        "- **Semantic + Hybrid**\n",
        "- **Semantic + Reranked Hybrid**\n",
        "\n",
        "---\n",
        "\n",
        "**Evaluation Metrics:**  \n",
        "Each configuration is evaluated using:\n",
        "- Recall@k\n",
        "- MRR (Mean Reciprocal Rank)\n",
        "- Precision@k\n",
        "- NDCG@k (Normalized Discounted Cumulative Gain)\n",
        "- Latency\n",
        "\n",
        "These metrics ensure a **fair and comprehensive comparison** across all chunking and retrieval strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRehQdp2Q9BK",
        "outputId": "6a7965e9-b057-41bc-af98-c35583093a59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fixed: 2045 chunks\n",
            "recursive: 2130 chunks\n",
            "semantic: 1880 chunks\n"
          ]
        }
      ],
      "source": [
        "results = {}\n",
        "\n",
        "for cname, chunk_fn in chunking_methods.items():\n",
        "    chunks = chunk_fn(full_text)\n",
        "    print(f\"{cname}: {len(chunks)} chunks\")\n",
        "\n",
        "    bm25 = create_bm25(chunks)\n",
        "    dense = create_dense(chunks)\n",
        "    hybrid = create_hybrid(bm25, dense)\n",
        "    reranked = create_reranked(hybrid)\n",
        "\n",
        "    retrievers = {\n",
        "        \"bm25\": bm25,\n",
        "        \"dense\": dense,\n",
        "        \"hybrid\": hybrid,\n",
        "        \"reranked\": reranked\n",
        "    }\n",
        "\n",
        "    for rname, retriever in retrievers.items():\n",
        "        metrics = evaluate_retriever(retriever, chunks)\n",
        "        results[(cname, rname)] = metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmE46DknemRX"
      },
      "source": [
        "# Final Comparison Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "SqKyPI4cRBDB",
        "outputId": "e9dc38de-e3a9-4414-e12c-796672a9a85f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12326754365545484,\n        \"min\": 0.1,\n        \"max\": 0.5372710622710622,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.31333333333333335,\n          0.1,\n          0.4769841269841269\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mrr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16341969017395272,\n        \"min\": 0.11666666666666667,\n        \"max\": 0.6133333333333333,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.28555555555555556,\n          0.5433333333333333,\n          0.26666666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10312295299468222,\n        \"min\": 0.05333333333333334,\n        \"max\": 0.3866666666666667,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.2800000000000001,\n          0.33333333333333337,\n          0.14666666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ndcg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17962544101448769,\n        \"min\": 0.1350449600579728,\n        \"max\": 0.7164881754274303,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.6537902876916198,\n          0.65642020087891,\n          0.1350449600579728\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3437103370897561,\n        \"min\": 0.004282013575236002,\n        \"max\": 0.9092674573262532,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.0232577641805013,\n          0.01771257718404134,\n          0.004997952779134115\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0cbff278-03f8-45f5-9433-5762fe24f885\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>recall</th>\n",
              "      <th>mrr</th>\n",
              "      <th>precision</th>\n",
              "      <th>ndcg</th>\n",
              "      <th>latency</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chunking</th>\n",
              "      <th>retriever</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">fixed</th>\n",
              "      <th>bm25</th>\n",
              "      <td>0.476984</td>\n",
              "      <td>0.548889</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.656420</td>\n",
              "      <td>0.004998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dense</th>\n",
              "      <td>0.321398</td>\n",
              "      <td>0.543333</td>\n",
              "      <td>0.253333</td>\n",
              "      <td>0.638409</td>\n",
              "      <td>0.017513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hybrid</th>\n",
              "      <td>0.434890</td>\n",
              "      <td>0.541667</td>\n",
              "      <td>0.306667</td>\n",
              "      <td>0.599131</td>\n",
              "      <td>0.022702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reranked</th>\n",
              "      <td>0.505525</td>\n",
              "      <td>0.613333</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.716488</td>\n",
              "      <td>0.697157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">recursive</th>\n",
              "      <th>bm25</th>\n",
              "      <td>0.499206</td>\n",
              "      <td>0.548889</td>\n",
              "      <td>0.346667</td>\n",
              "      <td>0.641039</td>\n",
              "      <td>0.005392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dense</th>\n",
              "      <td>0.308700</td>\n",
              "      <td>0.548889</td>\n",
              "      <td>0.253333</td>\n",
              "      <td>0.653790</td>\n",
              "      <td>0.017819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hybrid</th>\n",
              "      <td>0.346001</td>\n",
              "      <td>0.539444</td>\n",
              "      <td>0.280000</td>\n",
              "      <td>0.563227</td>\n",
              "      <td>0.023041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reranked</th>\n",
              "      <td>0.537271</td>\n",
              "      <td>0.613333</td>\n",
              "      <td>0.386667</td>\n",
              "      <td>0.701107</td>\n",
              "      <td>0.691394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">semantic</th>\n",
              "      <th>bm25</th>\n",
              "      <td>0.302222</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.146667</td>\n",
              "      <td>0.353850</td>\n",
              "      <td>0.004282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dense</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.116667</td>\n",
              "      <td>0.053333</td>\n",
              "      <td>0.135045</td>\n",
              "      <td>0.017713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hybrid</th>\n",
              "      <td>0.313333</td>\n",
              "      <td>0.285556</td>\n",
              "      <td>0.146667</td>\n",
              "      <td>0.353850</td>\n",
              "      <td>0.023258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reranked</th>\n",
              "      <td>0.335556</td>\n",
              "      <td>0.327778</td>\n",
              "      <td>0.173333</td>\n",
              "      <td>0.420516</td>\n",
              "      <td>0.909267</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cbff278-03f8-45f5-9433-5762fe24f885')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0cbff278-03f8-45f5-9433-5762fe24f885 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0cbff278-03f8-45f5-9433-5762fe24f885');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_4521333d-1856-4505-91e1-850a37196b04\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4521333d-1856-4505-91e1-850a37196b04 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                       recall       mrr  precision      ndcg   latency\n",
              "chunking  retriever                                                   \n",
              "fixed     bm25       0.476984  0.548889   0.333333  0.656420  0.004998\n",
              "          dense      0.321398  0.543333   0.253333  0.638409  0.017513\n",
              "          hybrid     0.434890  0.541667   0.306667  0.599131  0.022702\n",
              "          reranked   0.505525  0.613333   0.360000  0.716488  0.697157\n",
              "recursive bm25       0.499206  0.548889   0.346667  0.641039  0.005392\n",
              "          dense      0.308700  0.548889   0.253333  0.653790  0.017819\n",
              "          hybrid     0.346001  0.539444   0.280000  0.563227  0.023041\n",
              "          reranked   0.537271  0.613333   0.386667  0.701107  0.691394\n",
              "semantic  bm25       0.302222  0.266667   0.146667  0.353850  0.004282\n",
              "          dense      0.100000  0.116667   0.053333  0.135045  0.017713\n",
              "          hybrid     0.313333  0.285556   0.146667  0.353850  0.023258\n",
              "          reranked   0.335556  0.327778   0.173333  0.420516  0.909267"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(results).T\n",
        "df.index = pd.MultiIndex.from_tuples(\n",
        "    df.index,\n",
        "    names=[\"chunking\", \"retriever\"]\n",
        ")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We adopt **Recursive Chunking + Reranked Hybrid Retrieval** as our final configuration, based on evaluation results showing it delivers the best **Recall@k, MRR, and Precision@k**, while achieving second-best **NDCG@k**. Latency is not a primary concern for this application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uu2FIsEnWJcO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
